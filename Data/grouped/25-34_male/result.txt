 Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]] Continue reading  ]]   Yesterday, a very close friend wrote me a mail. It was strange for it was about, what I actually did in my last 9 months. Word by word, it turned out to be a touching reminiscence. Though I cant share with you the mail, the memories it refreshed are worth sharing. Yes, 9 months is not a coincidence. I worked on a conception. Not unilateral to make it sound mysterious ;) Thankfully, we delivered the baby who is growing well and spreading smiles in 2 interconnected forms. Dear close friend friends-to-be, I will devote time and share with you my sweet-sour experience and days as they pass. Thanks! My Quote Fish:  I would look at people in dire straits, crying and I would weep along in pity. I have now discovered a care-to-help-hanky  ]] /* Style Definitions */ table.MsoNormalTable{mso-style-name:"Table Normal";mso-tstyle-rowband-size:0;mso-tstyle-colband-size:0;mso-style-noshow:yes;mso-style-priority:99;mso-style-qformat:yes;mso-style-parent:"";mso-padding-alt:0cm 5.4pt 0cm 5.4pt;mso-para-margin-top:0cm;mso-para-margin-right:0cm;mso-para-margin-bottom:10.0pt;mso-para-margin-left:0cm;line-height:115%;mso-pagination:widow-orphan;font-size:11.0pt;font-family:"Calibri","sans-serif";mso-ascii-font-family:Calibri;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-fareast-theme-font:minor-fareast;mso-hansi-font-family:Calibri;mso-hansi-theme-font:minor-latin;} Let me begin today by taking you down the memory lane i.e. when 4 friends pursuing different jobs and assignments met over a bottle of Jack Daniels. As it turned out, we were not to have a fancy whiskey bottle for the next 9 months of our life because on that day, we just became entrepreneurs!! In next couple of weeks, there was no job, no foreseeable cash flows and hardly any savings. However, the idea of supporting and promoting arts seemed to be very inspiring. ]] /* Style Definitions */ table.MsoNormalTable{mso-style-name:"Table Normal";mso-tstyle-rowband-size:0;mso-tstyle-colband-size:0;mso-style-noshow:yes;mso-style-priority:99;mso-style-qformat:yes;mso-style-parent:"";mso-padding-alt:0cm 5.4pt 0cm 5.4pt;mso-para-margin-top:0cm;mso-para-margin-right:0cm;mso-para-margin-bottom:10.0pt;mso-para-margin-left:0cm;line-height:115%;mso-pagination:widow-orphan;font-size:11.0pt;font-family:"Calibri","sans-serif";mso-ascii-font-family:Calibri;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-fareast-theme-font:minor-fareast;mso-hansi-font-family:Calibri;mso-hansi-theme-font:minor-latin;} One of the friends got his houses emptied in Jaipur and very soon we had a roof. But the work on business could not begin until we had the basic amenities covered which included buying a fridge, a table, 4 chairs, a gas connection and a white board. These things formed first hard assets of the company and thus far have been our life-line without which we wouldnt sustain a day. This seemed weird at a time when we had just quit our multi-national jobs which enabled us to afford a fancy lifetime. Slowly, we realized that life was about to change...change quite drastically! ]] While the research stayed on internet, everything seemed hunky and dory. We even seemed to make a few nice contacts with NGOs quite fast. It appeared then that we would be able to develop some products and go out in the market by March 2013. As it turned out, in March 2013, we knew 1 artisan in total, no NGO that we knew could produce anything remotely close to what our target clientele wanted. In fact, we did not even know very clearly who our target clients could be. The lesson seemed quite clear..uncertainty is the most important planning input for entrepreneurs and flexibility is a pre-requisite for starting any business, more so, a social business. Know more about us at www.elementsmart.com ]] Chuttan, our only connect with artisan world after 3 months of our business did not trust us completely. It was amazing how nobody would believe our sacrifices let alone our vision, even after we repeatedly tried to convince them that we are working for their welfare. But we were determined and our patience eventually paid. In new couple of weeks, Chuttan became part of Elements family and we had the opportunity of sitting with his friends with Old Monk listening to their love stories. It is fascinating, how all the love stories, from different economic backgrounds share common themes of sacrifice, need to prove oneself and eternal passion. It has truly been a delight knowing Chuttan and all other artisans. It is their stories that motivate us every morning to give our 110% to our business. To know more about our artisans, please visit www.elementsmart.com ]] With some production support now we found a client for the business, a German beer beer company establishing themselves in India. With four people working on 1 deal, we were able to impress the client with our gift idea. This was despite the fact that we did not know photoshop or similar softwares to make the product design. A simple MS Paint drawing did it for us. Pumped by the order, we went all in with the production. At that time, production seemed to be a mathematical equation. You put in money and design as the input and the final product will be ready at the committed time. However, for a 1 week committed delivery time, 3 weeks from order, even the first sample for approval was not ready. We had just found out that these artisans who had been making images of deities for years, found it extremely difficult to make Bavarian statue. The client fortunately was a good friend and was not in a hurry and so we could afford this time. Literally, we had to sit with the artisans and motivate them to try and make something new. Half of the times, we would return home frustrated, exhausted and worst of, all empty handed. To see our finished products, please visit www.elementsmart.com ]] We slowly began to understand that offering customization is not a piece of cake and generating new ideas is not actually the newest thing. Like many many experienced individuals say, implementation is the key. We now made a conscious decision to discuss strategies less and get things done. This needed raising some money so artisans could be adequately compensated and motivated for their work. Implementation required being patient but not letting things loose i.e. we stopped getting discouraged with the bad samples and tried to understand the bottlenecks in the process. One such bottleneck was that the artisans were uneducated and through they could design beautiful paintings they could not write English alphabets. We sat with the artisans and created a new artistic form for writing the brand. Small successes like these helped our and the artisans confidence a great deal. A month after the scheduled delivery date we finally completed the order! We got a few thousand rupees for this and spent maybe double of what we received but the lessons learnt in the exercise were priceless. On this day, we finally knew what we had signed for and that not fancy strategies but field work, if we were to reach, could take us towards even moderate success. To know more about us, please visit www.elementsmart.com ]] Just reading the entire blog thread, I felt that we missed to present some good and encouraging moments that we have experienced in last 10 months, so today I talk about two of them and how they helped us take our first steps towards the MARKET. First such instance includes our initial meetings with Mrs. Runa Bannerjee of Sewa and Mrs. Komal Srivastava of Hunar. Veterans in the field of social development, especially artisan promotion, they initially doubted if we had the stamina to go the distance. But by the time they heard our story, the appreciation and hope in their eyes was inspiring for us. Outside the core team, they were the first believers in our idea and our vision. Those memories of pride and joy were all that kept us going in some extremely tough times. In hindsight, they feel even better and this is a joy, we believe, only entrepreneurs can relate to. Second was the instance when we delivered our first order to the client we mentioned in our previous blog. The satisfaction in our clients eyes and his appreciation of our efforts felt like a mozarts symphony (well at the team level, we appreciate Mika and Honey Singh more, but this appreciation had an eternal feel to it). I am sure my fellow entrepreneurs would agree with this feeling. Finally, the product reached the German ambassador in India, formed a part of brands expansion in Hong Kong. Slowly but surely, these small steps enabled us to achieve our first Proof of Concept! It is in fact these small successes that make entrepreneurship exciting for us!! To find out more about us, please see www.elementsmart.com ]] Its been a while since I last wrote coz last few weeks have been pulling us a like rubber band in all directions. Our sales team recently moved to Delhi to begin business development for corporate gifting. We have also established some foreign partnerships for business development that we are servicing currently but more on that later. For today, Id touch upon a topic all entrepreneurs like us face i.e. managing parents!! Yes, this can be one of the most draining exercises and I dont intend to offer any quick-fix solutions here but just share our experiences. A team of 5, we come from different backgrounds..business, service families and academicians. One constant though is that they all worry a lot and mostly are convinced that we wont go the distance. In the beginning, we make pretences of being the nicest kids around but slowly the business gets on to us and we are back to our normal selves smoking, drinking, listening to Niravana..so on and so forth. And then the faith dwindles down further and the conversations keep getting lesser and more awkward. Not to mention, months of no sales dont help and you are constantly told, we are telling you that this wont work out. Basically, every entrepreneur like us goes through a phase where we are almost convinced that entrepreneurship is the worst choice of our life. Dont get me wrong in any way, as I believe that this worry is perfectly reasonable and at all times, parents are our biggest strengths. In fact, it is a part of their worry that instils that sense of urgency in us..At Elements, we have constantly felt the need to prove to our parents and so far it has gone in our favour. When the small results begin to appear, the pride in their eyes is special. I believe what parents look for is sincerity and perseverance in you..and once they see that, they are relieved and that in itself is a proof that you are headed in the right direction. To know more about us, please visit www.elementsmart.com ]] Today I decided to write about a topic that we have had to deal with since jumping into mog of entrepreneurship, MOTIVATION. Yes, on countless occasions we have spent hours watching motivational videos from Steve Jobs Stanford speech to Al Pacinos inch by inch oration. My personal favourite is the dialogue between Stallone and Ventimiglia in the last film from the Rocky franchise. The question, however, that I ask myself is why has our appetite for such videos increased dramatically since becoming entrepreneurs. It is probably because the real world around appears to have become more thankless. Months of grueling has only enabled us to earn warm appreciation and numerous promises of our esteemed clients. We almost never seem to be on the right time or have THE product. The artisans, who form the basis of our existence, need to feed their families first and promises alone wont do that. Furthermore, feeding ourselves has become a daunting task these days. Our credit worthiness amongst friends has, deservingly, taken a serious nosedive. So we often seek solace in a packet of Maggi and these inspirational videos. I dont know if it provides sufficient proteins, calories and stuff but it makes us feel full! To add to the desperation, every now and then you hear of a friend who is traveling business class, staying in fancy hotels and so on..in these time, you just cant help but think  - I could have been there....You try and not say it out loud but you do think of it. Videos help, but temporarily.. So, how do we move on! Actually, till date, even I cant say with certainty how we continue. I must admit though that being in a team is a blessing and fortunately our low phases dont come together. Also, we seem to have become more thick skinned with experience and can therefore absorb more setbacks. However, the key for me has been the drive from inside, to make it large, not only for ourselves but also for our artisans. In our hearts, we are constantly reminded of the fact that entrepreneurship was never to be a piece of cake. The struggle has just begun and probably it would never end. In fact, the very fun lies in this game of hide and seek that we play with successes and failures on a daily basis. Only when we acknowledge this privilege that has been bestowed upon us, we start feeling alive again. I am hopeful that it is this anxiety in our hearts and dreams in our eyes that will propel us to travel to the end of the tunnel... coz in the end, it aint about how hard you hit, its about how hard you can get hit and keep moving forward.. To know more about us, please visit www.elementsmart.com ]] Greh (Planets) kharab hain sir!!, is currently the consensus within the team..The first Diwali at Elements and we could not celebrate it together. A series of unfortunate incidents, some forced choices and other constraints forced us to celebrate this Diwali in 5 different cities. We wonder how Goddess Lakshmi would react to that..but we will continue to keep our faith and bow down in front of her and apologize for any mistakes made, knowingly or unknowingly, and request her to create enough wealth for our stakeholders so that they all can have access to a life we deserve. We had planned a number of interesting messages and new products for this Diwali but as it stands today, our wall is empty. However, we truly wish and pray that all of you had a great Diwali and that the run to the next Diwali be even more amazing for you. Meanwhile, we also request you to stand by us as our Mangalyaan quickly corrects the positions of our stars..:-) Once again, wishing you and your loved ones..galaxy of smiles and joy!! Sincerely, All 5 Elements @ ELEMENTS Please read more about us at www.elementsmart.com ]] So we are back from our space mission and have already been through a number of Team building sessions (aka evenings with lassi and ice creams). To begin our diary again, I am sharing our experience with a positive side effect of being an entrepreneur, visibility. If you have put in good work and are reasonably smart, it is not so difficult to find people who are willing to write/talk about you. These chances are dramatically increased if you have ever been a business school student like me. Whatever be the reason, the feeling when IE Business School decided to write a blog on Elements was quite amazing and at that time, unbelievable. The two blogs published last year show a steady progression of Elements from being a concept in mid last year to a company which started taking shape in due course. We have not been very innovative in reaching out to more media platforms since then but hope to do so very soon. Meanwhile, as we relish these words of appreciation bestowed upon us by IE Business School, I invite you share a bit of our feelings by reading these blogs. May 2012 http://master-international.blogs.ie.edu/2012/05/25/2-mim-students-the-net-impact-weekend-and-one-idea-elements/ Nov 2012 http://master-international.blogs.ie.edu/2012/11/12/catching-up-with-elements/ To know more about us, please visit www.elementsmart.com ]]  openArchitectureWare. As you can see at the project's wiki site , I am almost finished implementing the required features. I implemented a protoypic eclipse integration using the Language Toolkit (LTK) first. This was (and still is :)) a prototype, since I wanted to focus my efforts on the algorithms the whole refactoring is based on. The UI sugar comes later ;). The implementation was easier than I thought. I became aquainted with the oAW source quickly, although it is commented very very raley :D. Very helpful were the Eclipse Type Hierarchy and Call Hierarchy . The Call Hierarchy is your perfect buddy for figuring out, how an API works. A screencast showing the refactorings Rename Extension and Rename DEFINE can be found here (.flv 22.6 mb). Note that it is in german .. it was not meant to be published .. just a little status report for my gsoc mentor peter .. but if you cannot wait to see the refacorings in action, go for it! I will publish another screen cast with even more cool features the coming days. I planned to finish the implementation of the refactoring algorithms by the end of this week. Right now I am working on the Move Extension feature. If this feature is implemented, I will take some days to clean up the code and make the abstractions clearer. Then I will start working on the user experience .. precondition checking, meaningful dialogs etc.]] here are news from the oaw code frontier. I finished implementing the move extension and rename resource feature. the move extension feature was trickier than I thought .. you not only have to delete the extension from the source file and insert it into the target file, you have to check which namespace and extensions are required to get the moved extension running within the target xtend file and you have to determine where to insert each import. I had a lot of MalformedTreeExceptions meaning that the insertions of new imports overlap or the inserted extension is not inside the document range :@! the tricky part of the calculation of the import offsets, the positions each import shall be inserted at, is the differentiation of different cases: is the target file empty, does it contain imports only, does it contain imports and extensions .. my code was covered with ugly nested, not understandable if-statements. to come up with this mess, I used the Strategy Pattern. the gof book says that it should be applied, if "different algorithms will be appropriate at different times". my base strategy class handles the common operations for the movement of an extension: remove the extension from the source file, update imports in all other files etc. it contains an abstract method called " createTargetFileChanges ", which has to be overridden by subclasses implementing a different insertion strategy. according to the target file's state, an appropriate strategy is chosen. the code is much clearer now and new cases can be handled (added) easier. A screencast showing the implemented features in action can be found here (.avi, 24.2 mb). the ui looks a little bit inconsistent and unhandy .. this is my next implementation step. I could not work that much the last days, since I got my admission for the master program at the hasso-plattner-institute for software systems engineering (YESSSS!) and I had to do a lot of administrative stuff .. get rid of my old flat, leave my old university. I planned to submit a paper about the modeling tool and distributed model simulation environment for information retrieval processes developed during my bachelor thesis to the mdsd today conference , but due to the upcoming gsoc deadline I will not have the time for writing one :(. So, during the next days I will focus my implementation efforts on the ui aspects of the oaw refactoring feature and finally I will test it using a real life oaw project. stay tuned! steven]] ANTLR and Micosoft's Phoenix framework I have to write a lot of C# code that lends itself to be generated. Besides the need for a java grammar, which can be found here , we need an AST (Abstract Syntax Tree) to accomplish the semantic analysis. ANTLR offers an AST construction mechanism and generates an AST walker from a tree grammar. Basically the semantic analysis can be done solely with ANTLR. But, we are facing the challenge that each teammate needs to work with the AST and not everyone knows ANTLR. Thus we need an ANTLR independent AST. The basis of our Java AST is the Eclipse JDT AST . My task is to implement the AST using C#. So, to implement means to copy since the JDT AST seems be a good model. Did I say model? This sounds like feeding the JDT AST code into a code generator and letting the generator create the C# implementation. Consequently we create a generator using openArchitectureWare that will take an UML2 class model, yes we decided to create an UML model of the AST ;), and generate C# classes. I sat down with a teammate having C# experiences to create the generator templates for generating C# code. Perfect! Now, our generator knows how to create C# classes .. and my teammate can go home :D. Furthermore we generate the basic visitor code for the AST from its model. By the way .. a language grammar lends itself to automatic AST generation .. check out this paper . Generators are knowledge containers! steven]] hi folks, I found an example application for Eclipse CDO . And I describe how to get it running. Download the latest Eclipse Modeling Tools: from Eclipse download choose Development Builds to get the latest tools. Fortunately, the site lets you know, that there are some problems for mac users with the 3.5M7 release. One problem is that there is no 'dropins' folder; but I will show you how we can bypass this problem (creating a folder named 'dropins' does not work :( ). Go get the Modeling tools! Additionally you need: the latest builds of CDO vers. 2.x (not 1.09!), Net4J vers. 2.x (not 1.09!), and Teneo . Download them, create a folder 'CDO_runtime' and copy all plugins found in the CDO, Net4j and Teneo builds into this folder. Next, save the Team Project Set file as 'cdo_example.psf' Now, start Eclipse of your Modeling Tools. In the Package Explorer right click- Import... -Team-Team Project Set and choose 'cdo_example.psf'. The next step is to add the cdo, net4j and teneo plugins to the Eclipse runtime. Normally, you do that by throwing them into Eclipse's 'dropin' folder which is absent in the current os x build. Therefore, we create a new Target Definition . Choose one of the CDO example projects, press CMD+N, choose Plug-in Development-Target Definition and name the file 'cdo_target'. Open the created 'cdo_target.target' file. In the upcoming editor press Add... , choose Installation-Next , type '${eclipse_home}' as location and press Finish . Now, we add our 'CDO_runtime' folder as location; so again press Add... , then choose Directory-Next , browse to this folder and press Finish . Finally, press Set as Target Platform in the upper right of the editor. At this point, all required plugins for the CDO example are installed. If you want to change your target platform back to the original Eclipse installation, open the preferences (CMD+,), choose Plug-in Development-Target Platform and select Running Platform . I did not have the time to play around with the example .. the installation took sooo long ;). I will post after further investigations have been done. Happy experimenting with CDO! greetzn, steven]] these days I was having problems with my CDO server: after inserting some models into a repository, and then restarting the server, I was getting this error: [ERROR] Rollback in DBStore: org.eclipse.net4j.db.DBException: SQL Exception: A lock could not be obtained within the time requested First, I thought, I forgot to commit/close a transaction; but this was not the case. In the emf news group, eike told me, that there was a similar problem in the tests based on apache derby. So, I switched to H2 , and the error did not occur anymore. I was desperately looking for the net4j H2Adapter in the latest net4j releases but was not able to find it. Finally, I found it here , copied to my workspace, and changed the creation of the IStore: org.h2.jdbcx.JdbcDataSource dataSource = new JdbcDataSource(); dataSource.setURL("jdbc:h2:~/h2Test"); IDBAdapter dbAdapter = new H2Adapter(); IMappingStrategy mappingStrategy = CDODBUtil.createHorizontalMappingStrategy(true); IDBConnectionProvider dbConnectionProvider = DBUtil.createConnectionProvider(dataSource); IStore store = CDODBUtil.createStore(mappingStrategy, dbAdapter, dbConnectionProvider); cheers, steven]] Hello, I need to create an eclipse plug-in project at runtime but don't know how! I think about reusing the New-Plug-in wizard , but after almost three hours of tweaking this wizard to fit my needs, I decided to do on my own! But wait, coding all this stuff .. create source folder, manifest folder, manifest file, plugin.xml file ... too much .. can't someone else do it?! praise opensource! I remember that oaw generates an eclipse-plug-in for you if you create a new oaw project. I go through oaw's cvs and find this promising class . After some minor modifications, e.g. removing the dependency to 'org.openarchitectureware.dependencies' in its createManifest(...) method, it does a perfect job! So, go get this class , adapt it to your needs and generate eclipse plug-in projects at runtime! bye, steven ]] I was looking for prices of internet domains, and found some numbers on this site . compare the rankings of .de (german domains) and .com domains. if you list the three most expensive .com domain names, you get this list: sex porn business for .de domains you get this one: kredit poker kasino If we assume that a domain price is a monetization of attention, we can interpret these list as follows: most of germany's attention can be caught on gambling sites, and of course on sites giving credit to player's. germans have no sex, just gambling they do not care about business, just gambling surprising: they do not care about unemployment, just gambling the rest of the world: is doing business otherwise just .. always trust the numbers! best, steven P.S. Sorry dear google user if you landed on this blog while searching for satisfaction! some words in this post do not have a common semantic ..]] This is a list of themes that will catch my attention during this semester: Protocol Compiler and Middleware Tracking of pharmaceutical products in supply chains Ad-hoc networks for embedded systems with AUTOSAR Linking in Xtext IT-Entrepreneurship Protocol Compiler and Middleware Together with Richard we will implement a middleware for The Wire Protocol in Java, and a protocol compiler. The protocol compiler will read a specification of a TWP protocol and generate code that implements the specified protocol on the basis of our middleware. The compiler will be built upon Xtext . Tracking of pharmaceutical products in supply chains This is my first research activity at the chair of Hasso Plattner , the founder of the HPI . I will investigate the efficient tracing of pharmaceuticals from production to the end-consumer. The goal of such a tracing is the verification of the authenticity of pharmaceuticals. So, if you are at the pharmacy, a pharmaceutical's way from the producer to your hands can be followed completely, and thus preventing you from taking pills produced in some of your neighbour's basement. Actual tracing mechanisms are too slow and I hope to find a way to make them faster. The exact title of my work is: "Algorithms and Data Structures for Data Capturing and Data Retrieval in the Context of EPC Discovery Services". Mobile Ad-hoc networks for embedded systems with AUTOSAR In the seminar Advanced Software Engineering for Embedded Systems I will develop an infrastructure for mobile ad-hoc networks for autonomous robots. The development will be based on AUTOSAR . Linking in Xtext The focus of my work for the seminar Software Design will be the linking-feature of Xtext. I will take a deep dive into the Xtext code to fully understand how the linker works. This should not be a big burden because I am already used to the (almost uncommented ;) )code written by Xtext developers since my google summer of code project in 2008 . After arising from the depths of the Xtext code I will conduct some experiments and thrill the world with Xtext's capabilities :D. IT-Entrepreneurship Last but not least I will write a business plan with Daniel and Toni. The cool thing about this seminar is that we are taught by Rouven Westphal . Rouven is a ... at Hasso Plattner Ventures (HPV) . HPV is a venture capital fund founded by - surpise :) - Hasso Plattner . So, Rouven's every day business is judging business plans; opposed to last year's teacher Prof. Wagner who took a too heavy weight theoretical approach to entrepreneurship - Prof. Wagner basically had no entrpreneurial spirit. Our first business idea is about increasing sales for food retailers. We think of a web platform that gives consumers access to retailers' shelfs in the digital world. Consumers create recipes that can be accessed by other consumers on their mobile devices in the store. The first effect is an increased shopping experience for customers: everything that is needed for a recipe is in one store - they do not have to go to a different store. And here comes the side door for retailers: if a retailer's stock is for instance full of salad that needs to be sold in one day and would be thrown away at the end of the day, the retailer places a special offer as a salad-recipe on the web-platform. This recipe will appear before any other recipe on customer's mobile devices when they enter the store. This has the effect that not only the salad is sold but also the other ingredients like cottage cheese, tomates, bread, and other stuff you need for a good salad. But these days I am thinking more and more about the iPhone as a platform for (IT-)Entrepreneurs. So many fellows are talking about iPhone App development - I never heard so many it-people talking about ONE platform for a basis for (fast) revenue. It's like a gold rush! And if there is a gold rush, invest in gold picks and shovels! But more to that in a later post.]] for those of you spending hours on trying to burn the bootloader on an atmega328 on your arduino , check out this . If you wonder, how to get to the screen shown in the above mentioned post: in avr studio, press the button looking like a microcontroller with the label "AVR": I am using AVRISP mkII and AVR Studio and it works perfectly. bye]] error C2275 illegal use of this type as an expression. check if you have declared a variable after the frist assignment in a function! remember: in c all variables have to be declared before any other statement. stop banging!]] I wanted git to ignore files that I have already added to the repository. Unfortunately, if a file was added, changing .gitignore does not help. But there are two options: git update-index --assume-unchanged [filename(s)] git update-index --skip-worktree [path_to_ignore] the first tells git to ignore changes to single files; the second tells it to ignore all files below a given path .. a complete directory. so far this works and I hope I did not mess something up. regards, s ]] just a redirect to this nice description of how to use value converters in xtext . s ]] world, check out this evaluation on CoreData Performance. s ]] check this out! ]] usepackage{caption} In your caption's you can add the ewline command: egin{figure} centering includegraphics{ } caption{Bla Bla Bla ewline Bla Bla Bla after line break} label{fig:aLabel} end{figure} regards ]] This post shows how I integrated uncrustify into Xtext . At the end of this post you will be able to package uncrustify with your language UI plugin and run uncrustify as part of a MWE2 workflow (the described approach was tested with Xtext 2.0 on Mac OS X 10.7). First, you have to get uncrustify . Unpack it, run ./configure and then make . The binary is located in the src/ folder and is named uncrustify - what a surprise. Create a folder formatting/ in your language's UI plugin. Copy the binary into this folder. To tell uncrustify how to format the code we have to supply it with a config file. A config file for objective c can be found here . Download this file and put it into the formatting/ folder. Besides the binary and a config file we need a shell script that runs uncrustify. Create a file formatSource.sh in formatting/ . The shell script looks like this: #! /bin/sh touch files.txt find . -name "*.[hm]" files.txt while read line; do ./uncrustify_osx -l OC -c ./uncrustify_obj_c.cfg --no-backup $line done files.txt rm files.txt This script will look for *.h and *.m files recursively down from its location, run over them, and format them without creating a backup copy. Now that we have the necessary files for running uncrustify ... oh well ... we must be able to run uncrustify from within java. For executing shell scripts from within a java process - welcome platform dependency - check out my ShellCommandExecutor . This class is also used for making the shell script formatSource.sh executable after copying it to a language project: private void copyFormattingFiles(final IProject project){ Bundle bundle = SystemDslActivator.getInstance().getBundle(); IPath scriptPath = copyFile("formatting/formatSource.sh" , "formatSource.sh", project, bundle); IPath binaryPath = copyFile("formatting/uncrustify_osx", "uncrustify_osx", project, bundle); copyFile("formatting/uncrustify_obj_c.cfg", "uncrustify_obj_c.cfg", project, bundle); //make script and binary executable try { ShellCommandExecutor.execute("chmod", "+x", scriptPath.toString()); ShellCommandExecutor.execute("chmod", "+x", binaryPath.toString()); } catch (Exception e) { //TODO: write to error log } } The above method can be found in this class . The execution of formatSource.sh in a MWE2 workflow component looks like this: public class ObjectiveCFormatter extends org.eclipse.emf.mwe.core.lib.AbstractWorkflowComponent2{ private static final String SCRIPT_PATH = "./formatSource.sh"; @Override protected void invokeInternal(WorkflowContext ctx, ProgressMonitor monitor, Issues issues) { try{ CommandResult cr = ShellCommandExecutor.execute(SCRIPT_PATH, new String[]{}); if (cr.success){ System.out.println("Formatting complete!"); } else{ issues.addError(cr.output); } }catch (Exception e){ issues.addError(e.getMessage()); } } } If you add this component after your objective c generator in your workflow all *.h and *.m files will be formatted as described by the uncrustify objective c config file . regards, steven ]] Xtext based modelling tool chain to model objective c (iPhone, iPad) applications for orderbird I needed to manipulate an Xtext model programmatically and serialize it back to disk. I did encounter some challenges while serializing enums and want to share my experience in this post. Here is a snippet of the grammar I am using for the well known use case of entity modelling: EntityModel: (entities += Entity)* ; Entity: (annotations+=Annotation)* 'entity' name=ID '{' '}' ; Annotation: '@' option=ConfigOption (':' value=ConfigValue)? ; enum ConfigOption: persistency ; enum ConfigValue: CoreData | FMDB ; So, entities can be annotated to determine with which technology they will be stored persistently. At first glance, serialization does not seem to be a hassle. Having an IResourceSetProvider , I can get the model from its XtextResource : @Inject private IResourceSetProvider provider; private EntityModel loadEntityModelFromFile(IFile file) { ResourceSet xrs   = provider.get(file.getProject()); URI uri           = URI.createPlatformResourceURI(file.getFullPath().toString(), true); Resource resource = xrs.getResource(uri, true); EntityModel em    = (EntityModel)resource.getContents().get(0); return em; } Now I can programmatically change the model and then serialize it back to disk by saving it in a XtextResource: private void save(EntityModel em) { ResourceSet xrs  = provider.get(getProject()); XtextResource xr = (XtextResource) xrs.getResource (URI.createPlatformResourceURI(getModelPath(), true) , true); xr.getContents().set(0, em); Map options = new HashMap (); SaveOptions.defaultOptions().addTo(options); xr.save(options); } Serializing this model: @persistency:CoreData entity Foo {} I get: @persistencyentity Foo {} The ConfigOption is missing! Hmmm, why? Xtext somehow assumes the ConfigOption to be transient (not serializable). The Xtext documentation says " The default transient value service considers a model element to be transient if it is unset or equals its default value. " and " By default, EMF returns false for eIsSet(..) if the value equals the default value. " Looking at the generated java code for the ecore meta model, the 'CoreData' literal is defined as the default: /* * @generated */ public class AnnotationImpl extends EObjectImpl implements Annotation { //... protected static final ConfigValue VALUE_EDEFAULT = ConfigValue.CORE_DATA; protected ConfigValue value                       = VALUE_EDEFAULT; //... } In order to tell Xtext which model elements can be considered as (non) transient, an instance of ITransientValueService has to be specified in your DSL's guice runtime module. This seems to be an easy task: Inherit from DefaultTransientValueService and overwrite isTransient(...) to yield the correct semantics: public class DataDslTransientValueService extends DefaultTransientValueService { @Override public boolean isTransient(EObject owner, EStructuralFeature feature, int index) { if (owner instanceof Annotation DataDslPackage.ANNOTATION__VALUE == feature.getFeatureID()) { return false; } return super.isTransient(owner, feature, index); } } ... and hook it into the guice module: public Class bindITransientValueService() { return DataDslTransientValueService.class; } Damn! Still the same errorneous output: @persistencyentity Foo {} A little bit of code archeology and debugging reveals that Xtext has two distinct hierarchies of the ITransientValueService interface. One in the package org.eclipse.xtext.parsetree.reconstr and the other in the package org.eclipse.xtext.serializer.sequencer . My DataDslTransientValueService implemented org.eclipse.xtext.parsetree.reconstr.ITransientValueService. But this does not seem to be sufficient. Thus, I also implemented org.eclipse.xtext.serializer.sequencer.ITransientValueService: @SuppressWarnings("restriction") public class SequencerTransientValueService extends TransientValueService { public ValueTransient isValueTransient(EObject semanticObject, EStructuralFeature feature) { if (semanticObject instanceof Annotation DataDslPackage.ANNOTATION__VALUE == feature.getFeatureID()) { return ValueTransient.NO; } return super.isValueTransient(semanticObject, feature); } } My DSL's guice runtime module contains these two bindings for ITransientValueService: public Class bindITransientValueService() { return DataDslTransientValueService.class; } public Class bindITransientValueService2() { return SequencerTransientValueService.class; } And finally the serialization yields the correct result! As you might have noticed I annotated the SequencerTransientValueService with @SuppressWarnings("restriction") . The class org.eclipse.xtext.serializer.sequencer.TransientValueService seems not be intended for public use. But obviously it is required to get the serialization to work correctly. At the time of writing this post, I also realized that my grammar's enum ConfigOption only has one literal that is defined as default and should thus not be serialized by default. But in my implementations of the two ITransientValueService interfaces I only specified ConfigValue to be non-transient. However, ConfigOption is serialized without adding the corresponding semantics to the implementations of the ITransientValueService. Maybe this is due to the Annotation's option attribute not being optional in the grammar as the value attribute is. And maybe I should study the Xtext documentation in more detail. Maybe .. Regards, steven ]] During christmas, I had a conversation with my uncle about orderbird which started like this: my uncle: "Why should someone invest in orderbird? orderbird is just a Point of Sale (POS) system !" me: "Because its not just a POS system. It will be THE platform provider for the gastronomy." my uncle: "Platform Provider? Are you going to produce oil rigs?" me: " ... No ... and ... No. orderbird will bring together all stakeholders relevant to gastronomy: gastronomists, guests,  suppliers. All of them will do their daily business with orderbird: Gastronomists run their restaurants with orderbird. Guests reserve tables, place orders, and pay with orderbird. For an optimal supply chain, suppliers and gastronomists work hand-in-hand with orderbird. " .. Ok, Ok, .. I must admit that the last elevator-pitch-part was added to make the dialog more appealing. Seriously, orderbird's business model can be classified as a Multi-Sided Platform (MSP) . It does not strictly follow the MSP pattern as defined in BMG . Here's why: Using a plain MSP business model, a MSP-company can hardly run profitabel without having customers that cover ALL customer segments that make up the MSP. Related to orderbird, this means that orderbird's business model would not work if orderbird only had gastronomists, only had guests, only had gastronomists and suppliers, and so forth. This is only partially true. Ok, if orderbird only had guests and suppliers, the business model should surely be adapted. But in some settings it can be built and scaled incrementally. While bringing one sutomer segment onto the platform, profits can be made without having to wait for another customer segment to enter the platform. Consider the current state of the evolution of orderbird's business model. orderbird has entered the german gastronomy market successfully having the 100st customer reachable at the end of the beta phase. Until a critical mass is reached, orderbird will improve its POS system to help gastronomists getting even more out of their business and tapping on the revenue streams generated from its POS system. While creating more value for gastronomists, orderbird is sketching and evaluating market entry strategies for bringing guests onto their platform. If a critical mass of customers is on the platform, the MSP model starts kicking! While offering guests an uncomplicated ordering and restaurant experience, gastronomists can profit from a better capacity utilization. And orderbird ... orderbird is tapping on a new revenue stream: guest ordering. For every placed order orderbird will receive a turnover percentage. If guests pay via orderbird, a turnover percentage on these transactions is imaginable, too. Besides the synergies among gastronomists and guests, the platform allows for better integration of gastronomists and supplier operations. Gastronomists will be able to choose from a variety of suppliers of beverages, food, and other goods they need to run their business. Suppliers can offer their products and services to a much broader audience. Let's sum things up. If you thought about investing in orderbird, do not base your thoughts and calculations on the assumption that you will invest in a company that simply delivers a POS system. orderbird's business model follows the pattern of a Multi-sided Platform (MSP): orderbird will bring together all relevant gastronomy stakeholders. This consolidation of stakeholders will give orderbird the possibility to get a share on multiple gastronomy related markets: POS systems, guest orders and reservations, guest payments, and supply chains. The orderbird platform will be THE marketplace for the gastronomy. Furthermore, what makes orderbird unique besides its business model is its team. The founder's talent and experience ranges from a deep understanding of the gastronomy market, to the planning and implementation of marketing and financial strategies, to a customer focussed development of software products. The founders are supported by a great team of software engineers, sales support people, designers, partners and board of directors. The spirit and success of orderbird is reflected by the awards we earned so far. I never felt so much enthusiasm and energy in a company!! Rock on!]] if you ask yourself how to open the Eclipse Properties View (PropertySheet) programmatically, I have an answer: PlatformUI.getWorkbench(). getActiveWorkbenchWindow(). getActivePage(). showView("org.eclipse.ui.views.PropertySheet"); "org.eclipse.ui.views.PropertySheet" is the view id of the Eclipse PropertyView (PropertySheet). regards, steven]] orderbird to analyze our code for potential thread safety issues. This post does not cover tools or strategies for multi-threaded programming but will point you to sources that cover this topic. 1) Threading Basics When your app is started iOS creates a new process and memory is allocated for this app-process. In simplified terms, the memory of an app-process consists of three blocks (A more detailed explanation of the memory layout of C programs can be found here ): The program memory stores the machine instructions your objective c code has been compiled to. Which instruction is executed next is indicated by the Instruction Pointer (IP). The heap stores objects which are created with [... alloc] init] . The stack is the memory area that is used for method invocations. Methods store things like their parameters and local variables on the stack. By default an app-process consists of one thread - the main thread. If your iOS app uses multiple threads, all threads share the program memory and the heap but each thread has its own instruction pointer and stack . This means that each thread has its own program flow and if a method is called on one thread, the parameters and local variables cannot be seen be any other thread. But the objects that are created on the heap can be seen, accessed, and manipulated by all threads . 2) Experiment Now, let us start our little experiment. Open Xcode and create a new project (choose the template "Empty Application"). Create a class named "FooClass" as depicted in the following: @interface FooClass {} @property (nonatomic, assign) NSUInteger value; - (void)doIt; @end @implementation FooClass @synthesize value; - (void)doIt { self.value = 0; for (int i = 0; i 100000; ++i) { self.value = i; } NSLog(@"after execution: %d (%@)", self.value, [NSThread currentThread]); } @end This class has an integer property named value that is incremented 100000 times in the doIt method. At the end of doIt self.value is logged to the console with the information on which thread doIt is executed. In order to execute the doIt method, create a method called _startExperiment in your project's AppDelegate and call this method in its application:didFinishLaunchingWithOptions: method: - (void)_startExperiment { FooClass *foo = [[FooClass alloc] init]; [foo doIt]; [foo release]; } - (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions { // ... [self _startExperiment]; return YES; } If we run our experiment by starting the iOS simulator (cmd + R), the _startExperiment method is called, an instance of FooClass is created on the heap and doIt is called on this instance. As expected, the console log (shift + cmd + c) shows 99999 for self.value . Nothing special so far: doIt is invoked on the main thread and it behaves as expected. 3) Thread Safety Let us execute doIt in parallel on multiple threads: - (void)_startExperiment { FooClass *foo = [[FooClass alloc] init]; dispatch_queue_t queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0); for (int i = 0; i 4; ++i) { dispatch_async(queue, ^{ [foo doIt]; }); } [foo release]; } If you execute this multi-threaded version of _startExperiment , you will get an output like this (the concrete values will differ from the output that I am posting): after execution: 19851 (NSThread: 0x6b29bd0{name = (null), num = 3}) after execution: 91396 (NSThread: 0x6b298f0{name = (null), num = 4}) after execution: 99999 (NSThread: 0x6a288a0{name = (null), num = 5}) after execution: 99999 (NSThread: 0x6b2a6f0{name = (null), num = 6}) Ouch ... not on all threads self.value is 99999 as we expected (If your execution produces a correct result - on all threads self.value is 99999 - re-execute it until an incorrect result is produced. It definitely will.). Why do not all threads produce a correct result? Well, because our code is not thread safe. Your code is thread safe if it behaves in the same way in a multi-threaded environment as it does in a single-threaded environment. As we observed above, the method doIt is not thread safe because it does not produce the same result in a multi-threaded environment as it does in a single-threaded environment. But what is the reason for this behavior? As stated in the beginning, each thread has its own instruction pointer (IP) and stack but all threads share the complete heap . Since the instance of FooClass is allocated on the heap and thus shared among all threads, the threads interfere while executing doIt . Let's take a closer  look at this interference. We consider the execution of the doIt method on two threads Thread1 and Thread2 : The instruction pointer (IP) of Thread1 points to the logging of self.value but did not execute the logging yet. At this point self.value is set to 99999. Now, Thread2 continues executing doIt . Its IP points to the assignment inside the for loop. We assume that self.value is set to 91396 in the for-loop on Thread2 . Uups. If Thread1 continues execution, self.value is not set to 99999 anymore but to 91396. Thread1 logs self.value and 91396 is printed. Since doIt does not prevent threads from interfering with each other while executing it, its implementation is not thread safe. One possible way to make doIt thread safe is to synchronize its body using the @synchronized compiler directive : - (void)doIt { @synchronized(self) { self.value = 0; for (int i = 0; i 100000; ++i) { self.value = i; } NSLog(@"after execution: %d (%@)", self.value, [NSThread currentThread]); } } Using the @synchronized directive, each thread gets exclusive access to self in doIt . Note that the threads cannot run in parallel anymore while executing doIt because the @synchronized directive covers the complete method body. Another way of syncing access to  shared state is to use Grand Central Dispatch (GCD) . 4) How to identify not thread safe code The experiment that I used to explain thread safety is an oversimplification of reality. In reality, you have already written your code, made some pieces run on background threads and from time to time your app is not behaving as expected. It freezes. It crashes. And you are not able to reproduce these issues. The main cause for threading issues is shared or global state. Multiple objects access a global variable, share the same object on the heap, or write to the same persistent store. In our little experiment the state that is shared among multiple threads is self respectively self.value . The identification of shared state is quite simple in our experiment but in a real world scenario it is quite hard to go through all your classes and identify methods that manipulate shared or global state. In order to make things easier I have written a convenient tool that identifies methods that are called from multiple threads. If I have the information which methods are called from multiple threads, I take a closer look at these methods. If such a method manipulates shared or global state, I make up a synchronization strategy for the state that is manipulated by this and other methods. In the following I will outline the core idea of this tool. The tool consists of four classes: the instances of MultiThreadingAnalysis record calls to methods on a specific thread, the classes ThreadingTrace and MethodExecution represent the result of conducting an analysis with MultiThreadingAnalysis , and the class MultiThreadingAnalysisHook is used to hook into an object and trace all method calls to this object. The class MultiThreadingAnalysis offers two methods: recordCallToMethod:ofClass:onThread: which records on which thread a method has been called. threadingTraceOfLastApplicationRun which should be called after the analysis has finished. @interface MultiThreadingAnalysis : NSObject - (void)recordCallToMethod:(NSString*)methodName ofClass:(NSString*)className onThread:(NSString*)threadID; - (ThreadingTrace*) threadingTraceOfLastApplicationRun; @end The result of a multi-threading analysis is an instance of ThreadingTrace . It consists of a set of MethodExecution instances each of which represents the execution of a method on a specific thread: /* * An instance of this class captures * which methods of which classes have been * called on which threads. */ @interface ThreadingTrace : NSObject /* * Set of MethodExecution */ @property (nonatomic, readonly) NSSet *methodExecutions; - (void)addMethodExecution:(MethodExecution*)methodExec; @end /* * An instance of this class represents a call * to a method of a specific class on a thread * with a specific threadID. */ @interface MethodExecution : NSObject @property (nonatomic, retain) NSString *methodName; @property (nonatomic, retain) NSString *className; @property (nonatomic, retain) NSString *threadID; @end In order to make the recording of method calls as convenient as possible I am using NSProxy to hook into method calls of an object. The class MultiThreadingAnalysisHook inherits from NSProxy and intercepts all calls to a target object in its forwardInvocation: method. Before forwarding a method call to the target object it records the call by using an instance of MultiThreadingAnalysis . @interface MultiThreadingAnalysisHook : NSProxy @property (nonatomic, retain) id target; @property (nonatomic, retain) MultiThreadingAnalysis *analysis; @end @implementation MultiThreadingAnalysisHook -(void)forwardInvocation:(NSInvocation*)anInvocation { [self.analysis recordCallToMethod:NSStringFromSelector([anInvocation selector]) ofClass:NSStringFromClass([self.target class]) onThread:[NSString stringWithFormat:@"%d", [NSThread currentThread]]]; [anInvocation invokeWithTarget:self.target]; } @end With the MultiThreadingAnalysisHook at your hands you can hook the multi-threading analysis into your code as proposed in the following. Create a private method _withThreadingAnalysis in the class that you want to analyze. This method creates an instance of MultiThreadingAnalysisHook and sets its target to self . In your designated initializer return the result of invoking _withThreadingAnalysis . The instance of MultiThreadingAnalysisHook will transparently wrap around self and record all calls to self without the need to change any other code outside of the class which you are analyzing. @implementation YourClass - (id)init { //... do init stuff here return [self _withThreadingAnalysis]; } - (id)_withThreadingAnalysis { MultiThreadingAnalysisHook *hook = [[MultiThreadingAnalysisHook alloc] init]; hook.target = self; return hook; } @end After you have installed the MultiThreadingAnalysis via the MultiThreadingAnalysisHook you can call threadingTraceOfLastApplicationRun on MultiThreadingAnalysis to get the trace and analyze respectively visualize it. A simple way of visualizing a trace is to produce a text file from it that looks like this: begin threading analysis for class FooClass method doIt (_ MultiThreadAccess _) method init (_SingleThreadAccess_) If a method is accessed from multiple threads (has the tag _MultiThreadAccess_), you can take a closer look at this method to check if it manipulates shared or global state and implement a suitable thread  synchronization strategy for the manipulated state. 5) Wrap up Your code is thread safe if it has the same behavior in a multi-threaded environment as it has in a single-threaded one. The reason for code not to be thread safe is the manipulation of shared or global state by multiple threads. Shared or global state can be a globally available persistent store, a singleton that is accessed  from multiple objects, or a global variable. The identification of methods that are accessed from multiple threads can be helpful to discover unsynchronized access to global or shared state and to devise a suitable synchronization strategy. The identification of such methods can be automated by leveraging the interception facilities of NSProxy , the recording of method calls, and the visualization of the recorded method calls. ]] Hi folks , if you ever wanted to found a start-up and are still looking for some advice, I recommend the following three books that helped me to sharpen my understanding of a start-up's nature and how to run it. The first one is Business Model Generation: A Handbook for Visionaries, Game Changers, and Challengers . This book will help you to define your initial product vision in terms of a business model. This books introduces you to a tool called the Business Model Canvas (BMC). The BMC will guide you step-by-step through the creation of a business model. Once you have defined your business model with the help of the BMC, you will find it much easier to communicate your vision to others and have a good starting point for your start-up. The second recommended reading is The Lean Startup by Eric Ries. Eric introduces you to a methodology - the Lean Startup Methodology -  which describes how you should run your start-up. While the Business Model Canvas is used to define your start-up's vision, the Lean Startup Methodology describes how you should implement this vision. It will help you in managing your precious time and money before running out of them. If you have never run a start-up before, you will find a perfect coach in Eric. Ash Maurya combines the Business Model Canvas and the Lean Startup Methodology in his book Running Lean . He presents an adopted version of the Business Model Canvas called the Lean Canvas and describes how you should apply the Lean Startup Methodology in conjunction with the Lean Canvas . Whilst the two previous books take a theoretical approach, this book takes a very practical approach. Ash takes you through the development of one of his start-ups step-by-step. He defines a Lean Canvas and walks you through the complete implementation of an initial product vision. If you have read "The Lean Startup" and cannot wait to apply the Lean Startup Methodology , read this book before you get your hands dirty. ]]  NB! This topic is mostly related to Java projects. The situation might be a little different in case of other technologies and IDEs. Just recently I had some discussions with the clients who were claiming that they keep IDE project files in version control system hence they avoid any changes to those files. For reference, those are Eclipse generated .project and .classpath . From my point of view it is a bad practice by all means, however I usually prefer to collect some information on the topic before I say it loudly. So I asked from my G+ and Twitter followers, IDE project files in version control - Yes/No? Surprisingly, I've got quite a number of responses, so I decided to summarize the information as a blog post. Basically, the answer to this question isn't binary, yes or no, but it also could be "yes, but... " or "no, if...". So there might be some argument why someone prefers one way or another. The vast majority of the answers is "No, no, noooooooo!! Never!". And just a couple of answers were "yes" with some weak arguments of why someone should keep those files in version control. Here are some yes answers first. Bad stuff. Seems that the team isn't really competent with the tools. The project should be easy to setup and why on earth I should press 100500 buttons to setup a project. If this is the case, the first thing that team lead should do, is to simplify the project structure, setup and build process. No excuses there. Yeah, yeah, I can already hear some arguments like "but we have a complex project" or "this is the way our setup is done". Bullsh*t! OK, there is some optimization for the setup, IDE specific though. If all the team members use the same setup, it might even make sense for those who want to keep hands off the console. Here's another one: "Specific Eclipse plugins" - yeah! that's is actually an argument for not keeping the files in version control! Eclipse plugins usually modify .project files as they add a "nature" or any other project specific settings to the configuration. And actually, IntelliJ does the same, but (let me bash to tools a bit) IntelliJ can suggest the settings as you open a project from scratch. And with Eclipse, you have to do that manually. What if your colleague uses some awesome eclipse plugin that makes modifications to .project file, and you hate that plugin and do not want to install it, and the .project file is in version control? Here's just a simple example that you could see while exporting a project with existing project files: This is so annoying to resolve this kind of problems. And all you want to do is just to open the project and proceed with your normal work. Here's more: Currently, I use IntelliJ and the rest of the team uses Eclipse. And I absolutely do not care if they put the project files into version control, because I will import it into my IDE in two clicks anyway. So the assumption that "absolutely yes, given that the team is working with the same IDEs" is wrong, and no viable argument here as well. However, here we have some much more interesting ideas: Wow, this is really interesting one - "those that define formatting or source code". Indeed! In cases when you work on varions projects for different clients, the requirements and code styles might be quite different and it makes sense even to keep this kind of files in version control, so you can share it with the team and restore the code style settings if you lost them. Good point here! However, you can probably see the vector of my post now. So the point is, IDEs support Maven quite well, so why on earth I would need to keep the IDE settings in version control if we already have what we need: pom.xml . IntelliJ and NetBeans cope with that quite well, and Eclipse also, if you use JBoss Tools . But what if I'm a Maven hater? (I really am). Here's an interesting conversation: Oh sure, Gradle that is! Well, the IDE support isn't there yet. Luckily, STS provides a nice Gradle plugin for Eclipse, but the support for IntelliJ and NetBeans isn't quite there yet. However, my claim is that Maven or Gradle isn't the prerequisite to avoid the project files in version control. The real prerequisite is the simple setup of you project and a clean structure, so that importing the project is just a couple of clicks. Then you can cope with any kind of project, even if it doesn't contain pom.xml. And here's what most of them say about the topic: Myself, I have tried both ways - keeping the project files in version control and not checking them in, and my take is that under no circumstances it is a good idea to check the project files in. Again, a much better solution is to keep your project structure clean and simple, which might be harder than to check the files into version control, but much more beneficial on the long run. Thanks everyone for the input! Take care... ]] JRebel team has produced a nice-looking PDF about Java classloaders . This should be a very nice read for everyone who wants to know more about Java platform fundamentals. ]] I had great fun speaking at Con-FESS today. Here are my slides for the Why Doesn't Java Have Instant Turnaround talk. The internet connection was great so I even managed to make a JRebel Remoting demo with Jelastic PaaS . After that, we had a great time investigating Griffon framework internals with Andres Almiray . Although it is quite tricky to update desktop applications on the fly, it seems it is still possible and Griffon will be able to leverage JRebel facilities. Peter Niederwieser talked about Gradle in the enterprise . Gradle is just about to go 1.0 which is great. The tooling is getting better and there are very nice features in Gradle that simplify build procedure and build script implementation - true incremental builds, autowiring, dsl extensions, etc. What is really missing at the moment is the stable way to migrate Maven projects to Gradle (there are some scripts, but these aren't quite stable) and the native release plugin. It is quite interesting that Gradle has implemented its own dependency management solution and isn't based on Ivy any more. Stefan Armbruster talked about using Grails with Neo4j graph database. It seems that it doesn't integrate that smoothly yet - some minor glitches still exist, but nevertheless it was used for a production application. Why Doesn't Java Has Instant Turnaround - Con-FESS 2012 View more PowerPoint from Anton Arhipov The video recording of the talk is available at Con-FESS website: http://2012.con-fess.com/sessions/-/details/139/Why-doesnt-Java-have-instant-turnaround ]] Here come the results for the last week's Java build tools survey. 675 people responded - thanks everyone who contributed! The answers were not mutually exclusive and a good portion of responders selected several answers. I interpret that as "I use Maven at work and Gradle at home". Or maybe there are multiple projects that the guys are working on and the old projects aren't migrated from Ant to Maven/Gradle. Anyways, here are the results: 480 out of 675 people indicated that they use Maven, which makes 71.1% out of all responders. Actually this number somehow matches my personal assumption about Maven share. Jason actually confirmed that this should be in line with the previous similar surveys: @antonarhipov Thats in line with other surveys for the last few years. The 60% is converging toward 85% Maven usage rate from Central.  Jason van Zyl (@jvanzyl) August 1, 2013 Gradle was used 235 people out of 675, which makes 34.8%. I was quite surprised by the number and I think this is due that the survey was mostly published via Twitter - I have some followers from Groovy/Gradle community. While I do believe that Gradle is getting momentum as a build tool, I really doubt that its share is high in Java enterprise/legacy projects. Ant (+Ivy) was mentioned by 114 responders and is at the third place with 16.9%. I think this number will be much much higher if we take only the legacy/enterprise projects. Maven vs Gradle vs Ant I think that there's no Maven vs Ant debate any more. Maven has won. Tooling support is (mostly) excellent and setting up a Maven projects in all major Java IDEs is (mostly) a no-brainer. There's definitely the Maven vs Gradle debate - there's plenty of details to debate about, which is better (at the moment of writing this post). But yet again, tooling support for Maven is the main argument why Maven is better. I think that without good IDE support Gradle won't overtake the build tools' market share , period. BTW , I'll keep the survey opened for some time - maybe it will get more responses. P.S. There's a good summary about the build tools at Rebel Labs , if you're interested. UPDATE: SBT was the 4th in the standings. 2.8% of respondents have indicated that they use SBT. ]] 33rd Degree conference have changed location this year. This time the action took place in Warsaw . It seems that 33rd Degree has outgrown its venue in Krakow and the organizers decided to pursue the possibility to expand the conference. The venue I realized that the venue "configuration" counts a lot. This time the conference was located equally on 2 floors of the Gromada Airport hotel. Actually it was a fair separation for both vendors and speakers, but there's a caveat. If the fancier sponsors are on the top floor and the most famous speakers are there as well, then the vendors who locate in the "bunker" should be worried. Actually the speakers who get to speak in the other floor should be worried as well. Literally, on the first day when I arrived, I could not wait in the line for a cup of tea at the top floor and at the same time it was dead empty at the bottom floor. This is just how the crowd moves, and it is very hard to fix it. My talks My first talk Do you really get your IDE? happened to take place at the bottom floor at the same time when a beer party was starting at the top floor. I was almost sure that noone will be interested in coming to the talk and my bet was that only 5-10 people would show up. I was totally wrong. The room was full. Very surprising. Since it was a BOF format and a lot time was consumed by conversations in the middle of the talk, I didn't really cover all the cool tricks that I wanted but I would count this talk pretty successful anyway - it was fun and entertaining. I hope I can "sharpen the saw" in delivering this talk a bit more since people really enjoy learning the tools. My second talk was about JRebel and how it can be used for updating Java applications. Not so many people came this time, probably because JRebel is a well known tool already and Baruch has dragged all the attendees in his talk instead. Other talks I usually don't attend that many sessions at the conferences since I know a lot of speakers personally and can learn from them directly in off-line conversations. However, this time I decided to go and listen and learn some cool stuff at the sessions. Leading the technical change by Nathaniel Schutta . The talk title and abstract did not fire up my curiosity. I just know that Nathaniel has a style delivering the presentations and I wanted to go and learn from his performance. The idea is very simple actually: instead of bullet points Nathaniel creates a slide per bullet point and makes it look attractive so that when the next slides comes he can see it from his laptop screen and then he knows what and how he should say. That is why the delivery is so smooth, no matter which topic he presents. Of course Nathaniel didn't skip the book he co-authored, the Presentation Patterns - very useful book for everyone who wants to present at the conferences. Being Honest - Rethinking Enterprise Java by Adam Bien. Adam is a very energetic speaker and I actually like his presentations about Java EE very much. But this time the technical aspects of the presentation didn't do good. The large room was full, but the screen was way too small for everyone to see the code. Plus the mic wasn't really working and it was quite hard to listen, so I could help myself but leave the room for some other talk. So I made it to the talk about Kotlin by Hadi Hariri . Kotlin's ecosystem is doing great steps forward. Unfortunately I didn't see the whole talk. In the part that I grasped this time Hadi was talking about the features that allow creating DSLs and he presented his own development, Spek , the specification framework for Kotlin. Scripted: Embracing Eclipse Orion by Martin Lippert . This was very unfortunate. Very nice talk about very nice tool with almost empty room. I call it "bad marketing". Martin is a good speaker and he talks about interesting topics, but it seems the title of the talk turned off the crowd. Who cares about Eclipse Orion at this kind of conference? Besides, nothing in the talk was really about Eclipse Orion. It was about Scripted - a kick-ass browser based JavaScript editor, very interesting RD project developed at SpringSource/VMWare. Programming with Lambda Expressions in Java by Venkat Subramaniam. Venkat's talks are so perfect it is hard to get a seat in the room. Attendees usually occupy the room in advance before the talk starts and those who are late steal the chairs from other rooms in order to get a seat. Nothing really advanced in the topic, but Venkat presents it with passion. Very entertaining. How we took our server-side application to the Cloud and liked what we got by Baruch Sadogursky . Very interesting talk for those who want to learn the basics of multy-tenancy and approaches in implementation for SaaS. Baruch talked about the solution they chose for the hosted version of Artifactory - what were the challenges and pitfalls. Overall 33rd Degree was definitely a success for the organizers but still there's plenty of details to improve: technical equipment would be the first on the list. Something needs to be done for managing the crowd - most of the time people are late for the sessions by a lot (with exception for the Venkat's talks). This is very distracting for the speakers, I think, even if they say it is not. The great thing about 33rd Degree is that Grzegorz works super-hard to organize it all: get the great (NFJS) speakers, cool vendors (Atlassian, Plumbr, JetBrains, etc), and the venue, which is actually very nice: plenty of space, great food, very close to the airport. plus, the price for the conference is still very affordable. ]] Mastering Java Bytecode - JAX.de 2012 ]] XPDays in Kiev was a success! Great crowd, interesting talks and fruitful discussions, socializing included. Embedded are the slides from by import continuous.delivery.* talk which was surprisingly well received and it seems a lot of people are looking for ways to release and deploy continuously, even in the large organizations. There are numerous different tools that could be used to organize the continuous delivery pipeline. The pipeline that I've demonstrated was built with Jenkins , Artifactory (Pro) and LiveRebel . I'm not super happy with the build pipeline plugin in Jenkins . In the talk I had to spend time explaining why the flow is organized the way it is and why the build pipeline plugin behaves the way it behaves. It is just buggy... I should find time to fix it. Arifactory's Pro version was just primarily because of the fact that artifact promotion feature is a Pro version and some of the REST APIs that I wanted to use were under Pro license. There are alternatives, but with Artifactory it was just much easier to show the relevant stuff. LiveRebel - well, there's no real alternative to it. The attendees were really impressed how easy it is to deploy via LiveRebel and oversee the target environment. The cool part is that all the tools integrate well via the REST API (or CLI) and you can build a very flexible pipeline if this kind of integration is available. What I also realized is that although everything can be automated in the pipeline, it shouldn't get on your way still - you should be able to go into any step and re-execute if needed. Another critical feature is the rollback functionality. It is not just that you select the previous version of the app if something goes wrong. There's more things you have to keep in mind when organizing the pipeline (I'm not revealing it now :P). Enjoy the slides! :) ]] Once again, I'm back to 33rd Degree conference, taking place in Warsaw on March 13-15. I'm going to have 2 talks there: Do you really get your IDE? , which is actually a BOF. This is my first time experience in running a BOF, so I'm not really sure how it turns out. I want to discuss with the folks, how the IDEs are used and how are the developers using the IDEs. I will play a bit with the code in IntelliJ IDEA and probably jump into other IDEs as well. Reloading Java applications like a Pro. At many conferences I've been talking about the very root of the turnaround problems in Java, the reasons and pitfalls. But this time I decided that it would be much more fun to showcase what JRebel can do for different types of Java applications. I plan to talk about the mechanics of the updates and what is happening inside Java application when JRebel is doing it work. Hopefully I can fit several demo scenarios into the talk: for Spring based application, for JavaEE, maybe something for non-conventional apps and desktop apps (e.g. JavaFX). I'm glad that 33rd Degree organizers allowed me to talk about JRebel directly. At many conferences the organizers are actually quite hesitant to accept any talks about commercial products. However, every time I give a talk on some technical topic, the attendees actually are eager to ask questions about JRebel rather than about the talk topic itself. It means that JRebel is more interesting, than, for instance, Java bytecode. So why bother about the commercial side of it? ]] In the previous post I wrote about managing the dependencies for IntelliJ IDEA plugin development and generating the project files. This was pretty simple and here's the full script: apply plugin: "java" apply plugin: "idea" repositories { jcenter() maven { credentials { username 'username' password 'password' } url "http://my.repository.url } } dependencies { compile('org.zeroturnaround:jr-sdk:5.4.1') { transitive = false } compile 'org.ow2.asm:asm-all:4.1' compile 'org.slf4j:slf4j-nop:1.6.3' compile 'org.apache.commons:commons-compress:1.2' } defaultTasks 'setup' idea.project.ipr { beforeMerged { project - project.modulePaths.clear() } } idea.module.iml { withXml { it.node.@type = "PLUGIN_MODULE" } } task setup { description = "crete .idea based project structure" dependsOn ideaModule, ideaProject doLast { copy { from '.' into '.idea/' include '*.ipr' rename { "modules.xml" } } project.delete "${project.name}.ipr" } } task wrapper(type: Wrapper) { gradleVersion = '1.8' } The script is only limited to pulling down the dependencies from binary repository and generating the project files . However, one really big thing is missing here, is the SDK setup. Adding the new SDK for plugin development is simple enough , but I still have a good reason to automate that. In my plugin, there's a dependency on some SDK artifacts that are not included into SDK classpath by default. So adding the dependencies one by one into the SDK via the UI is a bit tedious and not really encouraging for the team work. It would be cool if the script could register the IntelliJ Platform Plugin SDK and add it into the project files. It turns out that it should be doable as the SDK definitions are stored in options/jdk.table.xml file in IntelliJ IDEA's configuration directory . It might be a bit brittle to go tinkering with the file directly, so maybe JPS API could actually be used to add a new entry for the SDK. (just an idea) Those would be the steps for automating the setup: Fetch dependencies and generate .idea directory based project Generate Platform SDK entry to options/jdk.table.xml and add the reference to project *.iml file and .idea/misc.xml file Optionally, add more dependencies to Platform SDK definition The final step is the to add the build and release logic to the script Now, a little bit of dreaming :-) In the ideal world, the steps could be described as properties in build.gradle file: idea.module.type="PLUGIN_MODULE" - resolve as plugin module idea.project.sdk=auto (and idea.module.sdk=auto ) - auto-generate the SDK entry (with good defaults) and add it to the project and module The extra SDK dependencies are probably something that needs a special care. Don't know what could be the best workaround, but maybe something like this: idea.project.sdk.dependencies { lib1.jar lib2.jar lib3.jar } Build script would basically mimic the autogenerated the Ant file, and release step actually requires a bit more than just changing the version of the artifact: the version in META-INF/plugin.xml has to be updated as well. Dreaming aside, I think that the steps described above could be automated with a reasonable effort. So I better go and fork gradle idea plugin now... stay tuned :) ]] I'm speaking at JavaZone again this year. Hope to give an overview of javaagent and Instrumentation API with some referrals to the interesting use cases. ]] Although the Con-FESS conference attendance doesn't seem to be very high, around 200 people, it still was a good idea to come here. Look at this: Nice view, eh? :) First, I've attended to keynote talk by Jurgen Holler, Enterprise Java in 2012 and Beyond - From Java EE 6 to Cloud Computing . The talk was about the current trends towards cloud platforms. Cloud is a hot topic for Java EE 7 these days. The term "cloud" spawns across quite different technologies, not just Java. For instance, alternative datastores are quite popular among quite providers as these allow for better scalability. As the implementations are so different it is quite hard to imagine any reasonable standardization in this area. And even for Java, the vendors agree just on some bits of the standard, like Servlets, for instance. To my mind, the diversity will only grow in the cloud era. Also, it will be interesting to see how to tooling will evolve in some time. I'm quite sure that JBoss Tools and STS , as well as Google Eclipse plugin are aiming for this use case. With JRebel, it is now also possible to update application code in the cloud. I'm quite sure, in near future we will see some new tooling specially designed for the cloud apps but as the diversity is quite high, these tools will most likely be PaaS-specific. Next, I've attended the talk about Groovy ecosystem by Andres Almiray . It was an overview of the frameworks and libraries build with Groovy and for Groovy: Grails, Griffon, Gaelyk, Caelyf, Gradle, Gant, Codenark, GMetrics, Easyb. Not that much into the details, but a good overview. I learned a lot from Mark Struberg's talk about CDI and it really terrifies me how complex it might get with all the annotation-based programming model that CDI offers. Especially with the CDI extensions. Especially if people will start use this extensively. It is fine if people could stick with the libraries like CODI , Seam3 , or Apache DeltaSpike , but the perspective that the annotations are scattered across the source code and the developer can't see the full view at once really frightens me. Mark covered the standardization pitfalls as well as the gotchas when writing a CDI-based apps - very informative! He warned us from using @ApplicationScope for the beans as it isn't quite clear how this should work and the application containers can interpret this a bit differently, either for a whole EAR deployment or just for WAR deployment boundaries. It seems he had a lot more information to tell and he didn't fit everything in this talk, but we also had an interesting discussion afterwards. Here's a rage comic I came up with afterwards :) Last, I attended the talk about systems integration of could-based services by Kai Wahner . The presentation covered the introduction to Apache Camel and how it was used to integrate with Amazon Web Services and Google App Engine. The conference is hosted in Leogang, a small village not far from Salzburg, in Hotel Krallerhof . Surrounded with mountains, this place is amazing! ]] Java EE 7 was released just recently. And now it seems to be the time of preparing to the design on Java EE 8. There are already some whichlists published in the blogs: Antonio Goncalves' Java EE 8 wishlist Arjan Tijms - Java EE 8 wish list I might we wrong, but I don't remember seeing (or hearing) from anyone what is the ultimate goal of all these improvements. IMO, Java EE should take a look on Ruby-on-Rails or Play! and try to inspire from the coherent nature of those frameworks. Currently, my feeling is that Java EE looks like a collection of different specs that integrate with each other to a certain degree. But actually to be productive, one shouldnt care about the names of the specs (CDI, JAX-RS, EJB, etc), but instead just write the code. Java EE could just really align itself better with RoR. ]] GeekOUT conference started in 2011 as a local Java event. In 2013 it will be the 3rd coming for GeekOUT and the conference agenda is quite outstanding! There are 3 things about the conference that stand out: Agenda - 15 carefully selected talks. It is all about Java, JVM and JVM programming languages and tooling. Workshops - a dedicated day for hands-on workshops. DemoGrounds - a number of very cool vendors will be exhibiting: Hazelcast, CloudBees, Atlassian and more! However, one interesting thing about the conference is that it takes place in Tallinn . I can tell you for sure - Tallinn is absolutely awesome in June! Well, it usually is :) So if you are a Java developer and haven't been to Tallinn yet - now you have a good reason to visit the city! ]] Probably the most painful part in developing plugins for IntelliJ IDEA is the dependency management of the libraries that your plugin might depend on. There is a multitude of problems that one may encounter: IDEA binaries are not hosted publicly neither in Maven Central, JCenter, or any other repository. Plugins cannot be built with the common tools like Maven or Gradle without setting up your hair on fire. When your plugin depends on just a few external libraries, and the plugin build itself doesn't require customization, then everything is simple: put the dependencies into lib/ (or whatever) folder in the project and generate the Ant build script through Build - Generate Ant Build... action. Simple. Well, not really simple: the generated build script will require a few JARs from IDEA by pointing to the IDEA installation directory. So the simplest thing to do in this case is to extract the full IntelliJ IDEA distribution into some directory at the machine where the continuous integration server runs. Simple, ugly, but works. Why not to make things a bit more kosher? In my world, any developer in the team should be able to clone the project, open it in the IDE(A), and ideally, launch the project without any additional tuning. So what could we do in case of IntelliJ IDEA plugins projects? Store the *.iml files in VCS so that when the project is opened by another developer he would automatically have all the dependencies attached to the module? Not kosher . For me, clearly, the dependencies should be managed by dependency management tool. Options: Maven, Ivy, Gradle. IDEA provides a very good Maven support. But not for its own plugin modules. In fact, for plugin modules I wouldn't even try to use Maven as once IDEA recognizes it as a Maven project, it will erase the information about its plugin origin. Other options: Ivy and Gradle. Ivy is awesome. It works. There's also a nice plugin for IDEA that will automatically import the dependencies if it locates ivy.xml in the project directory. In that case you could still use the autogenerated Ant build script - just alter it a bit so that it would make a call to ivy task to get the dependencies and incorporate 'em into the build classpath. Sounds a bit too hardcore to me. There's a high chance that the project import will not be as smooth as you would like it to be. Especially if the project structure isn't very trivial. Gradle to the rescue! Gradle is awesome when it comes to non-trivial project structures. Its Ant-like flexibility along with nice Groovy syntax and all the Maven-like goodies is just awesome! First of all, managing dependencies is very easy. For instance: repositories { jcenter() } dependencies { compile('org.zeroturnaround:jr-sdk:5.4.1') { transitive = false } compile 'org.ow2.asm:asm-all:4.1' compile 'org.slf4j:slf4j-nop:1.6.3' compile 'org.apache.commons:commons-compress:1.2' } The little cool part is that JetGradle (in IDEA 12) would also automatically resolve and add the dependencies into the project. This is cool but it is not enough. First of all, JetGradle cannot import the project as an IDEA plugin module. Secondly, there's no JetGradle in IDEA 13 as Gradle integration is getting a major overhaul. OK, back to the drawing board. There's an 'idea' plugin for Gradle, how cool is that? Just run gradle idea and it will generate the project files, incorporating the references to the required dependencies. Good. But the generated module type is a Java module. And I need Plugin module . Have no fear, Gradle's here! We can easily customize the build script to adjust the XML project descriptor to our requirements. apply plugin: "idea" repositories { ... } dependencies { ... } idea.project.ipr { beforeMerged { project - project.modulePaths.clear() } } idea.module.iml { withXml { it.node.@type = "PLUGIN_MODULE" } } The withXml hook makes the magic here - instead of the auto-generated 'JAVA_MODULE' the final descriptor will contain 'PLUGIN_MODULE' which will make IDEA think that the module is an IntelliJ IDEA plugin. Only little problem that bothered me: the generated project descriptor is an *.ipr file that is kind of deprecated. It would have been much better if the plugin generated a directory based project metadata. The feature request was filed long ago but still isn't resolved. After experimenting with the project descriptors for a bit, I actually found a simple workaround for this minor annoyance. The .idea directory structure requires only modules.xml file that is identical to the *.ipr file that idea plugin generates. So I could just use this simple task to create directory based structure: task setup { dependsOn ideaModule, ideaProject doLast { copy { from '.' into '.idea/' include '*.ipr' rename { "modules.xml" } } project.delete "${project.name}.ipr" } } [hate mode="on"] Just writing delete "*.ipr" would not work. That's annoying. [hate mode="off"] So now I could just execute gradle setup and it would generate the directory based project structure, with the correct references to the required dependencies and I could import the project into IDEA without any hassle. This is all good. However, this is not the end of the story! There's more to do and more issues to resolve: Get the required IDEA internal artifacts to a local repository, so that these dependencies could also be downloaded via Gradle dependency manager. Migrate auto-generated Ant build script into Gradle script. Adopt the Gradle script to be able to manage the releases of the plugin. However, [hate mode="on"] none of this hassle would be needed if IntelliJ IDEA provided a sane way of building the plugins and managing the dependencies. [hate mode="off"] ]] br / ]] This is bit like a philosophical post. Just some thoughts regarding our perception of developer tooling. First - a question. Which IDE do you use? Eclipse? NetBeans? IntelliJ IDEA? Visual Studio? Vim? Emacs? Yeah, really - Vim counts as an IDE as long as you can configure it to behave like one. Or maybe Sublime Text, a really awesome text editor? Second question. Do you leverage the full power of your favourite IDE/editor? Mostly, people will say that the just use the IDE and I haven't really seen many people leveraging the power of refactorings, shortcuts, other awesome IDE features that are out there. Why? Lazy? Careless? Neglectful? I was reading a nice theory article The IDE Divide , which is already 8 years old. The point of the article is that it points out two extremes among the developers: language mavens and tooling mavens . Language mavens are those who case about the deepest nuances in the programming languages and don't really want to rely on tools (or just don't have time to explore the features of the tools). Tooling mavens are the ones who are obsessed with learning (and creating?) the tools and not spending as much time discovering the mysteries of language features. The article also mentioned that it is enormously hard to be both, the language maven and the tools maven at the same time, since the time for learning all this stuff is limited. But generally, I think, knowing the properties language and runtime is more important as it is the produced code that will eventually run on the system. The tools are just used to create the programs. However, I rather consider myself a "tooling maven" type of developer. Not that I don't care about the languages, no. It is just the interest shift towards tools for me. Despite the above, I noticed something (or it is just my perception). When a the new-born programmer starts, you will first try to reach the comfortable level of using the language. Once you're successful, there comes time for you to write the programs more effectively - faster, using shortcuts... click, click, click. This is where the tooling kicks in. Eventually, you start appreciate those nice features of your IDE that help you to write the code more effectively. The next stage is when you realize that actually you do not write code as much as you read it, and then you will start to appreciate the features that help you to navigate the code, analyze it, maybe refactor it. Language becomes a bit unimportant. I was chatting with Jacek Laskowski one day and he asked an interesting question: "If you're given awesome tools/components/frameworks to work with, would you really care about which programming language to use?" . Really good question. I wouldn't care, I guess. You will learn the language anyway. Or you will learn the tooling anyway once you're comfortable with the language of your choice, because normally you would like to be more effective (this is my perception of curious programmers, I hope you are a curious programmer). What do you feel when a colleague next to you just moves around the project like a pro and finds everything he needs just in fractions of a second, and types with shortcuts creating new statements with just a few strokes? And then you try to type: 'p' 'u' 'b' 'l' 'i' 'c' '_' 's' 't' 'a' 't' 'i' 'c' '_' 'v' 'o' 'i' 'd' '_' 'm' 'a' 'i' 'l' [oooops! a typo!]. Frustrating... It is every so often I was keeping myself back from screaming at my colleague "just Ctrl+Shift+E !!!!" while the team mate was looking for the class in the project tree the name of which he did not remember. Modern IDEs have revolutionized the way in which we are able to work with the code. Sadly, most programmers are held back by some mysterious myth that if you learn the tools too much you're doomed as a programmer as you start depending on those tools. Don't be held back by such fears! Go learn some tooling instead - it will save you some time later! ]] P.S. If the browser doesn't display the embedded survey frame, here's the direct link: http://www.surveymonkey.com/s/WLGLW2K P.S.2 BTW, I'm looking for volunteers to give the new JRebel Beta a try. If you're interested, please sign up here - we will start publishing the binaries soon. UPDATE: I've published the results here ]] At JavaZone I've presented a talk called Taming Java Agents . It is not about the distributed computing or messaging as the title might imply. It is about the tools that exercise -javaagent JVM argument to hook into class loading process in order to perform some necessary evil to the bytecode. The tools can do amazing things to the application by rewriting the bytecode - performance memory monitoring, class reloading , tracing , etc. I think this is an interesting topic in general - the tools do not exist for no reason. Here are the slides and the video from the talk: ]] A great article has been published at ZeroTurnaround's blog : Scala 2013: A Pragmatic Guide to Scala Adoption in Your Java Organization . You can download it as a PDF (which looks really cool!). The nice part is that it includes an interview with Martin Odersky and quotes by Josh Suereth . ]] In ZeroTurnaround we just launched a new page with awesome content collected in one place. RebelLabs hosts very nicely designed documents with interesting content produced by ZT engineers . My favorites so far are the reports on Scala adoption and Developers Productivity Report from 2012 ]] Its been more than a year since JRebel 5 has been released. During the year there have been a few minor releases and a lot of things were improved  remoting , debugger integration, support for more frameworks , IDE plugins, etc. Now, JRebel 6 is on the horizon. There will be several big changes (not revealing yet), which I hope will improve the UX very much. JRebel will be able to do things that it wasn't able to do before - that's very cool! Since it is a major release and there are a lot of changes that we introduced to the product, I'm looking for volunteers to try out the new beta version on real-life Java projects. You can register for the beta program here . If all goes as planned the first builds will land late August / early September. ]] The screencast demonstrates Maven integration features available in IntelliJ IDEA. Apache Camel maven archetype is used to generate the application. The main features are: Project setup automation and automatic dependency resolution Editor assistance and autocompletion Refactorings Dependency graph Lifecycle management using the tooling window ]] I've got 4 talks to deliver at JavaOne SF this year: UGF10388 - NetBeans Community Tools with JRebel, Jelastic and others. I'll be talking about our NetBeans plugin for JRebel - how it's made and what it does. CON2585 - Embedding JVM Scripting Languages. This talk has been brewing in my head for a long time now. It started at a time when I was investigating applicability business rule engines at my previous job. Amazingly, after some time I realized that in order to implement a BRMS, you actually have to have a very very very good reason. In most cases a rule engine can be as easy as a simple dynamic script that follows some conventions. Scripting languages on JVM allow just that! I'll be talking about embedding scripting into a Java app and assessing different options for the implementation. Will cover Groovy, JRuby and a bit of JavaScript too. CON2578 - Taming Java Agents. Since JRebel is stands on the shoulders of Instrumentation API and bootstraps via -javaagent VM argument, there's good portion of interesting things that I could talk about. Thankfully, Nikita will assist me as he's involved with Plumbr , which also based largely on Instrumentation API, however, it includes some native code as well. Combined, it will be an interesting overview of the underlying technology that enables us to develop awesome tools for Java platform. CON3477 - Apples and Oranges: The Highlights of Eclipse, IntelliJ IDEA, and NetBeans IDE. This will the showcase of all 3 major IDEs - NetBeans IDE, IntelliJ IDEA, and Eclipse (with JBoss Tools plugin). Geertjan suggested we do it together, so there will be 3 speakers, one for each IDE: Geertjan for NetBeans IDE, Max Andersen for Eclipse, and myself for IntelliJ IDEA. See You At JavaOne! ]] I've spent some time composing an overview of the new features in Java 8 . It includes the overview of lambda expressions in Java 8 and accompanying interesting features - default methods and bulk data operations for Java collections. I hope you will find the text interesting. ]] public draft of Java EE 7 has been uploaded. From the first sight, the new spec is rather an improvement of the subsequent specs in Java EE 6. For instance, I really like the Web Profile idea. But is is a shame that it wasn't a part of Java EE 6 Web Profile. The Web Profile is targeted at developers of modern web applications IMO, most of the modern web applications make use of REST. Or at least this is my perception. In Rails world, AFAIK, violating REST principle is a subject for brutal prosecution by the colleagues :) Luckily Java EE 7 fixes that mistake and JAX-RS specification is now a part of Web Profile. Targeting modern web applications then implies offering a reasonably complete stack, composed of standard APIs, and capable out-of-the-box of addressing the needs of a large class of web applications. OK, now you can really develop "modern" web apps with Web Profile, but... In terms of completeness, the Web Profile offers a complete stack, with technologies addressing presentation and state management. (JavaServer Faces, JavaServer Pages), core web container funtionality (Servlet), business logic (Enterprise JavaBeans Lite), transactions (Java Transaction API), persistence (Java Persistence API) and more. Sounds like redundancy to me. For instance, why would you need EJBs there? If CDI supported interceptors properly there wouldn't be a need for EJBs in that sense. Or, JSF? Well, I'm just not a fan of that. What I'm trying to say here is that since for compatibility reasons there wouldn't be possible to drop specs from Web Profile, maybe it is now time to create a "Light Profile"? A minimalistic set of Java EE specs that would be sufficient for building modern web applications. Of course the term is a bit foggy - what should we consider a modern web application . These days it is a combination of a REST backend and UI technologies such as HTML5 and JavaScript. My logic says that since Java EE doesn't specify UI technology then the main specification that required is JAX-RS and the complementary specifications to support transactions (JTA/JTS), persistance (JPA), and dependency injection (CDI). Of course, there are some nice complementary specifications such as Bean Validation and Java API for JSON processing. But I would definitely drop JSF and EJBs for sure. This would bring the containers like Tomcat and Jetty even closer to the spec and who knows maybe one day we will have a Java EE "Jetty Profile", why not :) ]]  Mistborn"Read more ]] The Crimson Campaign"Read more ]] Half a King finished, The First Law on the Horizon"Read more ]] The Desolation of Smaug"Read more ]] Read more ]] Raising Steam by Terry Pratchett"Read more ]] Persona 5 Announced for 2014 Release"Read more ]] Read more ]] The Thorn of Emberlain"Read more ]] Read more ]] Game of Thrones"Read more ]] The Chrysanthemum and the Dandelion"Read more ]] The Desolation of Smaug"Read more ]] Read more ]] Pippi Longstocking, The Strongest Girl in the World"Read more ]]  [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]] [Read the rest of the story at 20somethingfinance.com] ]]  Have you ever wondered what and how will you feel when you are left all alone in Karachi or Lahore when India and Pakistan are in war? If you like to experience the thrill of it, Danielle Steels's Silent honor is the book that you have to read rather experience. Hats off to steel for brining out such a beautiful book. Sneak Preview of the book: Hiroko, a traditional brought up Japanese girl goes to US to fulfill her dads wish of studying in States for at least a period of  1 year. She finds herself in a land filled with people of prejudice thoughts. None are friendly to her either in her school or other places. The only place where she was herself and enjoyed the most her cousins place. Thats where she gets to find her love, Peter. Tragedy strikes them soon after. Due to Japanese attack on the Pearl Harbour, the Japanese immigrants of US have to undergo huge turmoil. Does Hiroko manage to survive? How does she survive? Where does her fate land her? For more details read this interesting work. My Review: Its an excellent work from the author. I basically love war and love stories. This one has a good mix of both love and the sufferings of common people during war. The best part of this story is that the humor has been inserted and right places so that the movie is all that not serious. The love that the lead pair and other pairs share has been well brought out. But at times you feel as though the author has taken a longer route to explain the love, when there was a easier way of saying it.  All the characters in the story play an important and interesting part. The struggle that this little girl had to go through during the 2nd world war that too in the alien land where she totally hated and chased to the very corner of life has been described splendidly so that you really feel pity for her.I always loved the Japanese girls in the Jackie Chan movies i have seen  just because they look like dolls. But the heroine of the story also impressed me a lot with her determination, love and attitude.By reading this book you also get to know some of the Japanese terms ( chance to learn a foreign language ). The climax has also been drafted well showing the after effects of war. It also reminded me of some feel good Indian movies though. Over all it was a pleasant experience reading this book. ]] Sneak Preview of the Book : This is a beautiful scientific fiction thriller. Susan a beautiful Cryptographer who works for the NSA is being assigned a secret task of decoding a code (sent by an ex NSA employee) that was not even broken by the greatest code breaking machine "TRANSLTR" by her mentor Trevor Strathmore. As she goes about her job more and more mystery unfolds and she is caught in a trap. Her sweet heart David Becker is also in danger. How is the code finally broken then? How does she save herself and her fiancASis forms the rest of this exciting thriller from one of the well known writers. My Review: "Dan Brown what a author he is, chanceless dude".  "Awesome work from Dan Brown". These are some of the words that my friends uttered when they hear the name Dan Brown. This is the first book that i have read written by this author. And yeah i have to agree with my friends for sure. I love edge of the seat thriller movies, so is this story. No wonder his works like DA VINCI CODE and ANGEL and DEMONS have been made into movies. The way that this scientific thriller has been handled speaks volume of this author. The shifting of locations from America to Europe is pcture perfect and does not bore you a single minute. All the characters have been given equal space and equal importance. There are loads of twist in the story and keeps you excited all the time. The manner in which the mystery is finally revealed is also splendid i must say. I felt like i was watching a cool movie when i read this book. A must read for anyone who loves science and thriller. ]] I am sure Archer fans would have loved this book. This happens to the first one of his collections that i have read. ]] You should be cautious about every step that you take. The more you want to move away from something, the more it keeps coming near you. Can your passion and curiosity to explore the hidden truths land you in a big trouble? Everyone around you are in trouble because of you. How to get out of this mess? Just read Double Image by David Morrell. Sneak Preview of the book: Coltrane an award winning photographer whose job is to take photographs of the crimes committed by criminals in war ravaged countries. He escapes near death and some how manages to save his life. He wants to change track and start taking pictures to show beauty and not sorrow as he has been taking so far. But someone wants him dead and follows him like his shadow. Who is the killer? Does the killer succeed in his mission? My Review about the book: The crime thriller has enough stuff in it to keep you interested in reading the book. David Morrell has presented the thriller in a very interesting manner. But i donat know why the author has to combine 2 stories into one? I felt that the book was a master piece for the first half and the second half was just dragging taking us into a totally different plot. I probably think that the author thought that the second half if written as a separate book will not sell as this piece would have sold. Has there been a movie made(adapted) from this book? But i must say Bollywood directors will be itching to take this book to silver screen for sure. I would rate this say 6 out of 10. ]]  ]] ]] ]] ]] ]] ]] ]] ]] ]] ]]  ]] Just something I worked on for fun. ]] Some new works from my final project in my Advanced Perspective class. ]] Texture brushes exploration ]] ]] ]] A new environment piece for my thesis -- homeland of the male protagonist. ]] Some work I did for a recent art test. ]] ]] Some work I've done in Environment Design 2 at CGMA with James Paick. ]] Some recent work from James Paick's Environment Design 2 class at CGMA.  I've been incredibly busy lately with projects and class work, so I need to go back to these and polish them up more in the future. ]] ]] In the story the necromancer is only at his full power with this cursed weapon that feeds on his blood while corrupting him. ]] I'm learning Zbrush this semester, and man it has been a great learning experience doing digital sculpting.  Below are some WIPs, based off the released version of the main antagonist from my thesis.  The weapon is called "Devourer", and is an ancient malevolent and parasitic weapon that grants its bearer powers in exchange for a symbiotic relationship. ]]   